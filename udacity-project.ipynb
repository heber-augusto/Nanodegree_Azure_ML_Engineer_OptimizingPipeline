{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "experiment = Experiment(workspace=ws, name=\"train_bankmarketing\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = experiment.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-131774\n",
            "Azure region: southcentralus\n",
            "Subscription id: 61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\n",
            "Resource group: aml-quickstarts-131774\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1608934513901
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
        "                                                           max_nodes=4)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "# can poll for a minimum number of nodes and for a specific timeout. \n",
        "# if no min node count is provided it uses the scale settings for the cluster\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "# use get_status() to get a detailed status for the current cluster. \n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new compute target...\n",
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-12-25T22:16:31.384000+00:00', 'errors': None, 'creationTime': '2020-12-25T22:16:26.094721+00:00', 'modifiedTime': '2020-12-25T22:16:41.505104+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1608934601789
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a project directory**\r\n",
        "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. \r\n",
        "This includes the training script and any additional files your training script depends on."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "project_folder = './bankmarketing'\r\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608934634064
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Copy train.py script to project folder **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\r\n",
        "\r\n",
        "shutil.copy('train.py', project_folder)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "'./bankmarketing/train.py'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608936369927
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create an environment**\r\n",
        "\r\n",
        "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\r\n",
        "\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "\r\n",
        "sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608934658741
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\r\n",
        "** Configure the training job **\r\n",
        "\r\n",
        "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\r\n",
        "\r\n",
        "src = ScriptRunConfig(source_directory=project_folder,\r\n",
        "                      script='train.py',\r\n",
        "                      arguments=['--C', 1, '--max_iter', 100, '--solver', 'lbfgs'],\r\n",
        "                      compute_target=compute_target,\r\n",
        "                      environment=sklearn_env)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608936397540
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submit job**\r\n",
        "\r\n",
        "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = experiment.submit(src)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608936407231
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitor your run**\r\n",
        "\r\n",
        "You can monitor the progress of the run with a Jupyter widget. \r\n",
        "Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f00b6b725ab84957929e15b1aa03ba41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train_bankmarketing/runs/train_bankmarketing_1608936404_44036206?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131774/workspaces/quick-starts-ws-131774\", \"run_id\": \"train_bankmarketing_1608936404_44036206\", \"run_properties\": {\"run_id\": \"train_bankmarketing_1608936404_44036206\", \"created_utc\": \"2020-12-25T22:46:46.914442Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"09d9cbfa-f29a-460d-9681-1a34513c0d4c\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"resizing\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:01:49\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608936421733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: train_bankmarketing_1608936404_44036206\n",
            "Web View: https://ml.azure.com/experiments/train_bankmarketing/runs/train_bankmarketing_1608936404_44036206?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131774/workspaces/quick-starts-ws-131774\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling( {\n",
        "    \"--C\": choice(0.01, 0.1, 1, 10, 100),\n",
        "    \"--max_iter\": choice(100, 200, 500),\n",
        "    \"--solver\": choice('newton-cg', 'lbfgs', 'liblinear'),    \n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# Specify a Policy\n",
        "# The BanditPolicy basically states to check the job every 2 iterations. \n",
        "# If the primary metric (defined later) falls outside of the top 10% range, Azure ML \n",
        "# terminate the job. This saves us from continuing to explore hyperparameters that don't \n",
        "# show promise of helping reach our target metric.\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "# Create a SKLearn estimator for use with train.py\n",
        "# est = ### YOUR CODE HERE ###\n",
        "# I decided not to use the estimator because the documentation (https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.sklearn.sklearn) says that it is deprecated\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(\n",
        "    run_config=src,\n",
        "    hyperparameter_sampling=ps,\n",
        "    policy=policy,\n",
        "    primary_metric_name='Accuracy',\n",
        "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "    max_total_runs=20,\n",
        "    max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275789986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "# start the HyperDrive run\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitor HyperDrive runs**\r\n",
        "\r\n",
        "Monitor the progress of the runs with the following Jupyter widget."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert(hyperdrive_run.get_status() == \"Completed\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(best_run.get_details()['runDefinition']['arguments'])\n",
        "print(best_run.get_file_names())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598276310862
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(### YOUR DATA OBJECT HERE ###)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275726969
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=,\n",
        "    primary_metric=,\n",
        "    training_data=,\n",
        "    label_column_name=,\n",
        "    n_cross_validations=)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275665403
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}